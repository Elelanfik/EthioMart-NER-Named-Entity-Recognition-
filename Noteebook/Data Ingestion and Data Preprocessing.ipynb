{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ“Š Data Ingestion and Preprocessing for NER Model\n",
    "\n",
    "ğŸ¯ Objective\n",
    "\n",
    "Establish a data ingestion system to collect and preprocess messages from Ethiopian-based Telegram e-commerce channels for Named Entity Recognition (NER) tasks.\n",
    "\n",
    "ğŸ› ï¸ Approach\n",
    "\n",
    "1ï¸âƒ£ Data Ingestion\n",
    "\n",
    "- Channel Identification: Select at least five relevant Telegram channels focused on e-commerce.\n",
    "\n",
    "- Custom Scraper Development: Create a web scraper to automate the collection of messages, images, and documents from the identified channels.\n",
    "\n",
    "- Real-Time Data Collection: Implement a system to fetch data as it is posted, ensuring the dataset remains current.\n",
    "\n",
    "2ï¸âƒ£ Data Preprocessing\n",
    "\n",
    "- Text Normalization: Clean the collected text by converting it to a consistent format (e.g., lowercasing, removing special characters).\n",
    "\n",
    "- Tokenization: Split the text into individual tokens (words) for easier analysis.\n",
    "\n",
    "- Handling Amharic-Specific Features: Address unique linguistic characteristics of the Amharic language, such as diacritics and script variations.\n",
    "\n",
    "3ï¸âƒ£ Data Structuring\n",
    "\n",
    "- Metadata Separation: Organize the data by separating metadata (e.g., sender, timestamp) from the message content.\n",
    "\n",
    "- Unified Format Creation: Structure the cleaned data into a consistent format (e.g., CSV, JSON) for further analysis.\n",
    "\n",
    "4ï¸âƒ£ Quality Assurance\n",
    "\n",
    "- Data Review: Conduct a thorough review of the collected data to ensure completeness and accuracy, checking for any missing or corrupted entries.\n",
    "\n",
    "5ï¸âƒ£ Data Storage\n",
    "\n",
    "- Save Preprocessed Data: Store the cleaned and structured data in a suitable format for easy access during the labeling and model training phases.\n",
    "\n",
    "âœ… Summary of Steps\n",
    "\n",
    "1. Identify relevant Telegram channels.\n",
    "\n",
    "2. Develop a custom scraper for data collection.\n",
    "\n",
    "3. Preprocess the collected data.\n",
    "\n",
    "4. Structure and organize the data.\n",
    "\n",
    "5. Conduct quality assurance and store the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "    h1 {\n",
    "        color: #ffaa00;\n",
    "        text-shadow: 2px 2px 5px #000;\n",
    "        font-family: \"Comic Sans MS\", sans-serif;\n",
    "    }\n",
    "</style>\n",
    "\n",
    "<h1>âœ¨ Logging Setup Example in Python âœ¨</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "    h1 {\n",
    "        color: #ffaa00;\n",
    "        text-shadow: 2px 2px 5px #000;\n",
    "        font-family: \"Comic Sans MS\", sans-serif;\n",
    "    }\n",
    "</style>\n",
    "\n",
    "<h1>âœ¨ Importing Modules âœ¨</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "notebook_dir = os.getcwd()\n",
    "sys.path.append(os.path.abspath(os.path.join(notebook_dir, '..')))\n",
    "sys.path.append(os.path.abspath('../scripts'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.analysis import extract_messages_from_html_files, load_csv_to_dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "    h1 {\n",
    "        color: #ffaa00;\n",
    "        text-shadow: 2px 2px 5px #000;\n",
    "        font-family: \"Comic Sans MS\", sans-serif;\n",
    "    }\n",
    "</style>\n",
    "\n",
    "<h1>âœ¨ Loading Extracting Messages from telegram in CSV formâœ¨</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Channel Username    ID  \\\n",
      "0  @Shageronlinestore  6211   \n",
      "1  @Shageronlinestore  6210   \n",
      "2  @Shageronlinestore  6207   \n",
      "3  @Shageronlinestore  6206   \n",
      "4  @Shageronlinestore  6205   \n",
      "\n",
      "                                             Message  \\\n",
      "0  ğŸ’¥INIMA JAPAN COFFEE GRINDER\\n\\nğŸ’¯áŠ¨áá‰°áŠ› áŒ¥áˆ«á‰µ \\n\\nâš¡...   \n",
      "1  ğŸ’¥INIMA JAPAN COFFEE GRINDER\\n\\nğŸ’¯áŠ¨áá‰°áŠ› áŒ¥áˆ«á‰µ \\n\\nâš¡...   \n",
      "2  ğŸ’¥stainless still flower shape cake mold\\n\\nâš¡ï¸n...   \n",
      "3  ğŸ’¥Delux Foldable multifunctional Draying RACK\\n...   \n",
      "4  #áŠ áˆá‰†áˆ_áˆˆá‰°á‰£áˆ‹á‰½áˆ_á‰ á‹µáŒ‹áˆš_áŠ áˆµáŒˆá‰¥á‰°áŠ“áˆ \\nğŸ’¥Automatic rotatin...   \n",
      "\n",
      "                        Date  \n",
      "0  2025-01-17 06:59:57+00:00  \n",
      "1  2025-01-17 06:59:57+00:00  \n",
      "2  2025-01-16 13:41:31+00:00  \n",
      "3  2025-01-16 10:07:54+00:00  \n",
      "4  2025-01-16 09:20:43+00:00  \n"
     ]
    }
   ],
   "source": [
    "# Load the CSV into a pandas DataFrame\n",
    "telegram_data = load_csv_to_dataframe(r\"C:\\Users\\fikad\\Desktop\\10acedamy\\EthioMart-NER-Named-Entity-Recognition-\\Data\\telegram_data.csv\")\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(telegram_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "    h3 {\n",
    "        color: #ff1199;\n",
    "        text-shadow: 2px 2px 5px #000;\n",
    "        font-family: \"Comic Sans MS\", sans-serif;\n",
    "    }\n",
    "</style>\n",
    "\n",
    "<h3>âœ¨ checking NAN and cleaning itâœ¨</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel Username</th>\n",
       "      <th>ID</th>\n",
       "      <th>Message</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>6211</td>\n",
       "      <td>ğŸ’¥INIMA JAPAN COFFEE GRINDER\\n\\nğŸ’¯áŠ¨áá‰°áŠ› áŒ¥áˆ«á‰µ \\n\\nâš¡...</td>\n",
       "      <td>2025-01-17 06:59:57+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>6210</td>\n",
       "      <td>ğŸ’¥INIMA JAPAN COFFEE GRINDER\\n\\nğŸ’¯áŠ¨áá‰°áŠ› áŒ¥áˆ«á‰µ \\n\\nâš¡...</td>\n",
       "      <td>2025-01-17 06:59:57+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>6207</td>\n",
       "      <td>ğŸ’¥stainless still flower shape cake mold\\n\\nâš¡ï¸n...</td>\n",
       "      <td>2025-01-16 13:41:31+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>6206</td>\n",
       "      <td>ğŸ’¥Delux Foldable multifunctional Draying RACK\\n...</td>\n",
       "      <td>2025-01-16 10:07:54+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>6205</td>\n",
       "      <td>#áŠ áˆá‰†áˆ_áˆˆá‰°á‰£áˆ‹á‰½áˆ_á‰ á‹µáŒ‹áˆš_áŠ áˆµáŒˆá‰¥á‰°áŠ“áˆ \\nğŸ’¥Automatic rotatin...</td>\n",
       "      <td>2025-01-16 09:20:43+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>@helloomarketethiopia</td>\n",
       "      <td>4210</td>\n",
       "      <td>áŠ¥áŠ•áŠ³áŠ• áˆˆáŠ á‹²áˆ± á‹“áˆ˜á‰µ á‰ áˆ°áˆ‹áˆ áŠ á‹°áˆ¨áˆ³á‰½áˆ!\\ná‹¨áˆáŒ†á‰½ á‹¨áŠ•á‰£á‰¥ áŠ¥áŠ•á‹²áˆáˆ á‹¨á‰€...</td>\n",
       "      <td>2024-09-18 14:39:51+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>@helloomarketethiopia</td>\n",
       "      <td>4209</td>\n",
       "      <td>áŠ¥áŠ•áŠ³áŠ• áˆˆáŠ á‹²áˆ± á‹“áˆ˜á‰µ á‰ áˆ°áˆ‹áˆ áŠ á‹°áˆ¨áˆ³á‰½áˆ!\\náˆˆá€áŒ‰áˆ­á‹ áˆáˆµáˆ‹áˆ³áˆ´á¡ áŒ áŠ•áŠ«áˆ¬ ...</td>\n",
       "      <td>2024-09-18 09:05:51+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>@helloomarketethiopia</td>\n",
       "      <td>4208</td>\n",
       "      <td>áŠ¥áŠ•áŠ³áŠ• áˆˆáŠ á‹²áˆ± á‹“áˆ˜á‰µ á‰ áˆ°áˆ‹áˆ áŠ á‹°áˆ¨áˆ³á‰½áˆ!\\náˆˆáˆáˆˆá‰±áˆ á†á‰³ á‹¨áˆšáˆ†áŠ• á‰ áŒ€áˆ­á‰£...</td>\n",
       "      <td>2024-09-17 18:00:11+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>@helloomarketethiopia</td>\n",
       "      <td>4207</td>\n",
       "      <td>áŠ¥áŠ•áŠ³áŠ• áˆˆáŠ á‹²áˆ± á‹“áˆ˜á‰µ á‰ áˆ°áˆ‹áˆ áŠ á‹°áˆ¨áˆ³á‰½áˆ!\\náŠ¨áˆ¸áˆ« á‹¨á‰°áˆ°áˆ« á‹¨áˆáŒ†á‰½ á‹¨áˆáˆ³áŠ¥...</td>\n",
       "      <td>2024-09-17 15:18:21+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>@helloomarketethiopia</td>\n",
       "      <td>4206</td>\n",
       "      <td>áŠ¥áŠ•áŠ³áŠ• áˆˆáŠ á‹²áˆ± á‹“áˆ˜á‰µ á‰ áˆ°áˆ‹áˆ áŠ á‹°áˆ¨áˆ³á‰½áˆ!\\náŠ¥áŠ•á‹²áˆ… á‹µáˆá‰… á‹«áˆˆ á‰£áˆ…áˆ‹á‹Š á‹¨...</td>\n",
       "      <td>2024-09-16 14:40:20+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Channel Username    ID  \\\n",
       "0       @Shageronlinestore  6211   \n",
       "1       @Shageronlinestore  6210   \n",
       "2       @Shageronlinestore  6207   \n",
       "3       @Shageronlinestore  6206   \n",
       "4       @Shageronlinestore  6205   \n",
       "..                     ...   ...   \n",
       "995  @helloomarketethiopia  4210   \n",
       "996  @helloomarketethiopia  4209   \n",
       "997  @helloomarketethiopia  4208   \n",
       "998  @helloomarketethiopia  4207   \n",
       "999  @helloomarketethiopia  4206   \n",
       "\n",
       "                                               Message  \\\n",
       "0    ğŸ’¥INIMA JAPAN COFFEE GRINDER\\n\\nğŸ’¯áŠ¨áá‰°áŠ› áŒ¥áˆ«á‰µ \\n\\nâš¡...   \n",
       "1    ğŸ’¥INIMA JAPAN COFFEE GRINDER\\n\\nğŸ’¯áŠ¨áá‰°áŠ› áŒ¥áˆ«á‰µ \\n\\nâš¡...   \n",
       "2    ğŸ’¥stainless still flower shape cake mold\\n\\nâš¡ï¸n...   \n",
       "3    ğŸ’¥Delux Foldable multifunctional Draying RACK\\n...   \n",
       "4    #áŠ áˆá‰†áˆ_áˆˆá‰°á‰£áˆ‹á‰½áˆ_á‰ á‹µáŒ‹áˆš_áŠ áˆµáŒˆá‰¥á‰°áŠ“áˆ \\nğŸ’¥Automatic rotatin...   \n",
       "..                                                 ...   \n",
       "995  áŠ¥áŠ•áŠ³áŠ• áˆˆáŠ á‹²áˆ± á‹“áˆ˜á‰µ á‰ áˆ°áˆ‹áˆ áŠ á‹°áˆ¨áˆ³á‰½áˆ!\\ná‹¨áˆáŒ†á‰½ á‹¨áŠ•á‰£á‰¥ áŠ¥áŠ•á‹²áˆáˆ á‹¨á‰€...   \n",
       "996  áŠ¥áŠ•áŠ³áŠ• áˆˆáŠ á‹²áˆ± á‹“áˆ˜á‰µ á‰ áˆ°áˆ‹áˆ áŠ á‹°áˆ¨áˆ³á‰½áˆ!\\náˆˆá€áŒ‰áˆ­á‹ áˆáˆµáˆ‹áˆ³áˆ´á¡ áŒ áŠ•áŠ«áˆ¬ ...   \n",
       "997  áŠ¥áŠ•áŠ³áŠ• áˆˆáŠ á‹²áˆ± á‹“áˆ˜á‰µ á‰ áˆ°áˆ‹áˆ áŠ á‹°áˆ¨áˆ³á‰½áˆ!\\náˆˆáˆáˆˆá‰±áˆ á†á‰³ á‹¨áˆšáˆ†áŠ• á‰ áŒ€áˆ­á‰£...   \n",
       "998  áŠ¥áŠ•áŠ³áŠ• áˆˆáŠ á‹²áˆ± á‹“áˆ˜á‰µ á‰ áˆ°áˆ‹áˆ áŠ á‹°áˆ¨áˆ³á‰½áˆ!\\náŠ¨áˆ¸áˆ« á‹¨á‰°áˆ°áˆ« á‹¨áˆáŒ†á‰½ á‹¨áˆáˆ³áŠ¥...   \n",
       "999  áŠ¥áŠ•áŠ³áŠ• áˆˆáŠ á‹²áˆ± á‹“áˆ˜á‰µ á‰ áˆ°áˆ‹áˆ áŠ á‹°áˆ¨áˆ³á‰½áˆ!\\náŠ¥áŠ•á‹²áˆ… á‹µáˆá‰… á‹«áˆˆ á‰£áˆ…áˆ‹á‹Š á‹¨...   \n",
       "\n",
       "                          Date  \n",
       "0    2025-01-17 06:59:57+00:00  \n",
       "1    2025-01-17 06:59:57+00:00  \n",
       "2    2025-01-16 13:41:31+00:00  \n",
       "3    2025-01-16 10:07:54+00:00  \n",
       "4    2025-01-16 09:20:43+00:00  \n",
       "..                         ...  \n",
       "995  2024-09-18 14:39:51+00:00  \n",
       "996  2024-09-18 09:05:51+00:00  \n",
       "997  2024-09-17 18:00:11+00:00  \n",
       "998  2024-09-17 15:18:21+00:00  \n",
       "999  2024-09-16 14:40:20+00:00  \n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telegram_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for NaN values in the 'Message' column:\n",
      "Number of NaN values in 'Message' column: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Checking for NaN values in the 'Message' column:\")\n",
    "nan_count = telegram_data['Message'].isnull().sum()\n",
    "print(f\"Number of NaN values in 'Message' column: {nan_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      ğŸ’¥INIMA JAPAN COFFEE GRINDER\\n\\nğŸ’¯áŠ¨áá‰°áŠ› áŒ¥áˆ«á‰µ \\n\\nâš¡...\n",
       "1      ğŸ’¥INIMA JAPAN COFFEE GRINDER\\n\\nğŸ’¯áŠ¨áá‰°áŠ› áŒ¥áˆ«á‰µ \\n\\nâš¡...\n",
       "2      ğŸ’¥stainless still flower shape cake mold\\n\\nâš¡ï¸n...\n",
       "3      ğŸ’¥Delux Foldable multifunctional Draying RACK\\n...\n",
       "4      #áŠ áˆá‰†áˆ_áˆˆá‰°á‰£áˆ‹á‰½áˆ_á‰ á‹µáŒ‹áˆš_áŠ áˆµáŒˆá‰¥á‰°áŠ“áˆ \\nğŸ’¥Automatic rotatin...\n",
       "                             ...                        \n",
       "995    áŠ¥áŠ•áŠ³áŠ• áˆˆáŠ á‹²áˆ± á‹“áˆ˜á‰µ á‰ áˆ°áˆ‹áˆ áŠ á‹°áˆ¨áˆ³á‰½áˆ!\\ná‹¨áˆáŒ†á‰½ á‹¨áŠ•á‰£á‰¥ áŠ¥áŠ•á‹²áˆáˆ á‹¨á‰€...\n",
       "996    áŠ¥áŠ•áŠ³áŠ• áˆˆáŠ á‹²áˆ± á‹“áˆ˜á‰µ á‰ áˆ°áˆ‹áˆ áŠ á‹°áˆ¨áˆ³á‰½áˆ!\\náˆˆá€áŒ‰áˆ­á‹ áˆáˆµáˆ‹áˆ³áˆ´á¡ áŒ áŠ•áŠ«áˆ¬ ...\n",
       "997    áŠ¥áŠ•áŠ³áŠ• áˆˆáŠ á‹²áˆ± á‹“áˆ˜á‰µ á‰ áˆ°áˆ‹áˆ áŠ á‹°áˆ¨áˆ³á‰½áˆ!\\náˆˆáˆáˆˆá‰±áˆ á†á‰³ á‹¨áˆšáˆ†áŠ• á‰ áŒ€áˆ­á‰£...\n",
       "998    áŠ¥áŠ•áŠ³áŠ• áˆˆáŠ á‹²áˆ± á‹“áˆ˜á‰µ á‰ áˆ°áˆ‹áˆ áŠ á‹°áˆ¨áˆ³á‰½áˆ!\\náŠ¨áˆ¸áˆ« á‹¨á‰°áˆ°áˆ« á‹¨áˆáŒ†á‰½ á‹¨áˆáˆ³áŠ¥...\n",
       "999    áŠ¥áŠ•áŠ³áŠ• áˆˆáŠ á‹²áˆ± á‹“áˆ˜á‰µ á‰ áˆ°áˆ‹áˆ áŠ á‹°áˆ¨áˆ³á‰½áˆ!\\náŠ¥áŠ•á‹²áˆ… á‹µáˆá‰… á‹«áˆˆ á‰£áˆ…áˆ‹á‹Š á‹¨...\n",
       "Name: Message, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telegram_data_df=telegram_data['Message']\n",
    "telegram_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "    h2 {\n",
    "        color: #ffaa00;\n",
    "        text-shadow: 2px 2px 5px #000;\n",
    "        font-family: \"Comic Sans MS\", sans-serif;\n",
    "    }\n",
    "</style>\n",
    "\n",
    "<h2>âœ¨   Extracting Unique Characters from a CSV Column âœ¨</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique characters found:\n",
      "['\\n', ' ', '!', '\"', '#', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '=', '>', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '|', '~', '\\xa0', 'Â®', 'Â°', 'Ã—', 'áˆ€', 'áˆ', 'áˆ‚', 'áˆƒ', 'áˆ„', 'áˆ…', 'áˆ†', 'áˆˆ', 'áˆ‰', 'áˆŠ', 'áˆ‹', 'áˆŒ', 'áˆ', 'áˆ', 'áˆ', 'áˆ’', 'áˆ•', 'áˆ˜', 'áˆ™', 'áˆš', 'áˆ›', 'áˆœ', 'áˆ', 'áˆ', 'áˆŸ', 'áˆ ', 'áˆ£', 'áˆ¨', 'áˆ©', 'áˆª', 'áˆ«', 'áˆ¬', 'áˆ­', 'áˆ®', 'áˆ¯', 'áˆ°', 'áˆ±', 'áˆ²', 'áˆ³', 'áˆ´', 'áˆµ', 'áˆ¶', 'áˆ¸', 'áˆ¹', 'áˆ»', 'áˆ¼', 'áˆ½', 'áˆ¾', 'á‰€', 'á‰', 'á‰‚', 'á‰ƒ', 'á‰„', 'á‰…', 'á‰†', 'á‰‹', 'á‰ ', 'á‰¡', 'á‰¢', 'á‰£', 'á‰¤', 'á‰¥', 'á‰¦', 'á‰§', 'á‰¨', 'á‰ª', 'á‰«', 'á‰­', 'á‰®', 'á‰°', 'á‰±', 'á‰²', 'á‰³', 'á‰´', 'á‰µ', 'á‰¶', 'á‰·', 'á‰¸', 'á‰¹', 'á‰º', 'á‰»', 'á‰¼', 'á‰½', 'á‰¾', 'áŠ‹', 'áŠ', 'áŠ‘', 'áŠ’', 'áŠ“', 'áŠ”', 'áŠ•', 'áŠ–', 'áŠ˜', 'áŠ™', 'áŠ›', 'áŠ', 'áŠ', 'áŠ ', 'áŠ¢', 'áŠ£', 'áŠ¤', 'áŠ¥', 'áŠ¦', 'áŠ¨', 'áŠ©', 'áŠª', 'áŠ«', 'áŠ¬', 'áŠ­', 'áŠ®', 'áŠ³', 'á‹ˆ', 'á‹‰', 'á‹Š', 'á‹‹', 'á‹Œ', 'á‹', 'á‹', 'á‹’', 'á‹“', 'á‹•', 'á‹˜', 'á‹™', 'á‹š', 'á‹›', 'á‹œ', 'á‹', 'á‹', 'á‹Ÿ', 'á‹¢', 'á‹£', 'á‹¨', 'á‹©', 'á‹ª', 'á‹«', 'á‹¬', 'á‹­', 'á‹®', 'á‹°', 'á‹±', 'á‹²', 'á‹³', 'á‹´', 'á‹µ', 'á‹¶', 'áŒ€', 'áŒ', 'áŒ‚', 'áŒƒ', 'áŒ…', 'áŒ†', 'áŒ‡', 'áŒˆ', 'áŒ‰', 'áŒŠ', 'áŒ‹', 'áŒŒ', 'áŒ', 'áŒ', 'áŒ', 'áŒ“', 'áŒ ', 'áŒ¡', 'áŒ¢', 'áŒ£', 'áŒ¤', 'áŒ¥', 'áŒ¦', 'áŒ§', 'áŒ¨', 'áŒ©', 'áŒª', 'áŒ«', 'áŒ­', 'áŒ®', 'áŒ¯', 'áŒ´', 'áŒµ', 'áŒ¸', 'áŒ»', 'áŒ½', 'á€', 'á', 'á‚', 'áƒ', 'á…', 'á†', 'áˆ', 'á‰', 'áŠ', 'á‹', 'áŒ', 'á', 'á', 'á', 'á', 'á’', 'á“', 'á”', 'á•', 'á–', 'á¡', 'á¢', 'á£', 'á¤', 'á¥', 'á¦', 'â€”', 'â€™', 'â€œ', 'â€', 'â€¢', 'â€³', 'â€¼', 'âƒ£', 'â„¢', 'â°', 'â²', 'â—', 'â˜„', 'â˜', 'â˜‘', 'â˜•', 'â™¥', 'â™¦', 'âš ', 'âš¡', 'âœ…', 'âœ', 'âœ”', 'âœ–', 'âœ¨', 'â‡', 'âŒ', 'â“', 'â—', 'â¤', 'â¡', 'â¤µ', 'â­', 'ï¸', 'ï¸', 'ğ—”', 'ğ—•', 'ğ—–', 'ğ——', 'ğ—˜', 'ğ—™', 'ğ—š', 'ğ—œ', 'ğ—Ÿ', 'ğ—¡', 'ğ—¢', 'ğ—£', 'ğ—¥', 'ğ—¦', 'ğ—©', 'ğ—ª', 'ğ—°', 'ğ—±', 'ğ—²', 'ğ—µ', 'ğ—¶', 'ğ—¹', 'ğ—»', 'ğ—¼', 'ğ—½', 'ğ—¿', 'ğ˜€', 'ğ˜', 'ğ˜‚', 'ğ˜„', 'ğ™—', 'ğ™£', 'ğ™¤', 'ğ™­', 'ğŸ…', 'ğŸ…‘', 'ğŸ…’', 'ğŸ…“', 'ğŸ…”', 'ğŸ…–', 'ğŸ…—', 'ğŸ…˜', 'ğŸ…›', 'ğŸ…œ', 'ğŸ…', 'ğŸ…', 'ğŸ…Ÿ', 'ğŸ…¡', 'ğŸ…¢', 'ğŸ…£', 'ğŸ…¤', 'ğŸ…¥', 'ğŸ…¨', 'ğŸ…°', 'ğŸ†•', 'ğŸ‡ª', 'ğŸ‡·', 'ğŸ‡¸', 'ğŸ‡¹', 'ğŸ‡º', 'ğŸŒ', 'ğŸŒ', 'ğŸŒŸ', 'ğŸŒ®', 'ğŸŒ²', 'ğŸŒ»', 'ğŸ€', 'ğŸ•', 'ğŸ–', 'ğŸ—', 'ğŸŸ', 'ğŸ¸', 'ğŸ¼', 'ğŸ½', 'ğŸ¾', 'ğŸ', 'ğŸ„', 'ğŸ†', 'ğŸ¥', 'ğŸ©', 'ğŸ¯', 'ğŸ¢', 'ğŸ·', 'ğŸ½', 'ğŸ¾', 'ğŸ€', 'ğŸ›', 'ğŸ‘€', 'ğŸ‘‡', 'ğŸ‘ˆ', 'ğŸ‘‰', 'ğŸ‘‹', 'ğŸ‘Œ', 'ğŸ‘', 'ğŸ‘', 'ğŸ‘”', 'ğŸ‘Ÿ', 'ğŸ‘ ', 'ğŸ‘¸', 'ğŸ’…', 'ğŸ’Š', 'ğŸ’¥', 'ğŸ’¦', 'ğŸ’§', 'ğŸ’ª', 'ğŸ’«', 'ğŸ’¬', 'ğŸ’¯', 'ğŸ’°', 'ğŸ’²', 'ğŸ’´', 'ğŸ’µ', 'ğŸ’»', 'ğŸ“ƒ', 'ğŸ“ˆ', 'ğŸ“Œ', 'ğŸ“', 'ğŸ“™', 'ğŸ“', 'ğŸ“£', 'ğŸ“©', 'ğŸ“±', 'ğŸ“²', 'ğŸ”„', 'ğŸ””', 'ğŸ”–', 'ğŸ”˜', 'ğŸ” ', 'ğŸ”¤', 'ğŸ”¥', 'ğŸ”°', 'ğŸ”´', 'ğŸ”¼', 'ğŸ”½', 'ğŸ•·', 'ğŸ–Œ', 'ğŸ–¥', 'ğŸ—„', 'ğŸ—“', 'ğŸ—¯', 'ğŸ˜€', 'ğŸ˜', 'ğŸ˜', 'ğŸ˜', 'ğŸ˜®', 'ğŸ˜±', 'ğŸ˜²', 'ğŸ˜³', 'ğŸ™ˆ', 'ğŸš›', 'ğŸš©', 'ğŸ›', 'ğŸ›', 'ğŸ›’', 'ğŸ›¡', 'ğŸŸ ', 'ğŸŸ¢', 'ğŸ¤', 'ğŸ¤¨', 'ğŸ¤«', 'ğŸ¥“', 'ğŸ¥›', 'ğŸ¥', 'ğŸ¥Ÿ', 'ğŸ¥§', 'ğŸ¥©', 'ğŸ¥®', 'ğŸ¥µ', 'ğŸ¦—', 'ğŸ¦Ÿ', 'ğŸ§†', 'ğŸ§Š', 'ğŸª', 'ğŸª°', 'ğŸª³', 'ğŸ«“', 'ğŸ«•']\n"
     ]
    }
   ],
   "source": [
    "# Combine all rows in the 'Address' column into a single string\n",
    "combined_text = \" \".join(telegram_data[\"Message\"].astype(str))\n",
    "\n",
    "# Find unique characters\n",
    "unique_chars = sorted(set(combined_text))\n",
    "\n",
    "# Print the unique characters\n",
    "print(\"Unique characters found:\")\n",
    "print(unique_chars)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "    h3 {\n",
    "        color: #ff1199;\n",
    "        text-shadow: 2px 2px 5px #000;\n",
    "        font-family: \"Comic Sans MS\", sans-serif;\n",
    "    }\n",
    "</style>\n",
    "\n",
    "<h3>âœ¨   Extracting Unique Characters from a CSV Column âœ¨</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel Username</th>\n",
       "      <th>ID</th>\n",
       "      <th>Message</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>6211</td>\n",
       "      <td>INIMA JAPAN COFFEE GRINDER\\n\\náŠ¨áá‰°áŠ› áŒ¥áˆ«á‰µ \\n\\n150...</td>\n",
       "      <td>2025-01-17 06:59:57+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>6210</td>\n",
       "      <td>INIMA JAPAN COFFEE GRINDER\\n\\náŠ¨áá‰°áŠ› áŒ¥áˆ«á‰µ \\n\\n150...</td>\n",
       "      <td>2025-01-17 06:59:57+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>6207</td>\n",
       "      <td>stainless still flower shape cake mold\\n\\nnon ...</td>\n",
       "      <td>2025-01-16 13:41:31+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>6206</td>\n",
       "      <td>Delux Foldable multifunctional Draying RACK\\n\\...</td>\n",
       "      <td>2025-01-16 10:07:54+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>6205</td>\n",
       "      <td>áŠ áˆá‰†áˆáˆˆá‰°á‰£áˆ‹á‰½áˆá‰ á‹µáŒ‹áˆšáŠ áˆµáŒˆá‰¥á‰°áŠ“áˆ \\nAutomatic rotating noz...</td>\n",
       "      <td>2025-01-16 09:20:43+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Channel Username    ID  \\\n",
       "0  @Shageronlinestore  6211   \n",
       "1  @Shageronlinestore  6210   \n",
       "2  @Shageronlinestore  6207   \n",
       "3  @Shageronlinestore  6206   \n",
       "4  @Shageronlinestore  6205   \n",
       "\n",
       "                                             Message  \\\n",
       "0  INIMA JAPAN COFFEE GRINDER\\n\\náŠ¨áá‰°áŠ› áŒ¥áˆ«á‰µ \\n\\n150...   \n",
       "1  INIMA JAPAN COFFEE GRINDER\\n\\náŠ¨áá‰°áŠ› áŒ¥áˆ«á‰µ \\n\\n150...   \n",
       "2  stainless still flower shape cake mold\\n\\nnon ...   \n",
       "3  Delux Foldable multifunctional Draying RACK\\n\\...   \n",
       "4  áŠ áˆá‰†áˆáˆˆá‰°á‰£áˆ‹á‰½áˆá‰ á‹µáŒ‹áˆšáŠ áˆµáŒˆá‰¥á‰°áŠ“áˆ \\nAutomatic rotating noz...   \n",
       "\n",
       "                        Date  \n",
       "0  2025-01-17 06:59:57+00:00  \n",
       "1  2025-01-17 06:59:57+00:00  \n",
       "2  2025-01-16 13:41:31+00:00  \n",
       "3  2025-01-16 10:07:54+00:00  \n",
       "4  2025-01-16 09:20:43+00:00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import emoji\n",
    "import re\n",
    "\n",
    "\n",
    "# Function to clean the text (remove emojis, symbols, etc.)\n",
    "def remove_emoji(text):\n",
    "    if isinstance(text, str):\n",
    "        return emoji.replace_emoji(text, replace='')\n",
    "    return text\n",
    "\n",
    "def remove_symbols(text):\n",
    "    if isinstance(text, str):\n",
    "        return re.sub(r'[^A-Za-z0-9áˆ€-á\\s]+', '', text)\n",
    "    return text\n",
    "\n",
    "# Apply cleaning functions to 'Message' column\n",
    "telegram_data['Message'] = telegram_data['Message'].apply(remove_emoji).apply(remove_symbols)\n",
    "display(telegram_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "    h1 {\n",
    "        color: #ffaa00;\n",
    "        text-shadow: 2px 2px 5px #000;\n",
    "        font-family: \"Comic Sans MS\", sans-serif;\n",
    "    }\n",
    "</style>\n",
    "\n",
    "<h1>âœ¨    Named Entity Recognition (NER) Labeling Functionâœ¨</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fikad\\Desktop\\10acedamy\\EthioMart-NER-Named-Entity-Recognition-\\Week-5\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline \n",
    "#Load the tokenizer and model for NER\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mbeukman/xlm-roberta-base-finetuned-amharic-finetuned-ner-amharic\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"mbeukman/xlm-roberta-base-finetuned-amharic-finetuned-ner-amharic\")\n",
    "\n",
    "# Set up NER pipeline\n",
    "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to map NER model results to CoNLL format labels\n",
    "def map_ner_to_conll(ner_results, tokens):\n",
    "    labels = ['O'] * len(tokens)  # Initialize labels as 'O' (Outside)\n",
    "    \n",
    "    for entity in ner_results:\n",
    "        word = entity['word'].replace('##', '')  # Remove subword artifacts from NER results\n",
    "        entity_type = entity['entity']  # Extract entity type\n",
    "        \n",
    "        # Define mapping for NER entity types\n",
    "        label = 'O'  # Default label\n",
    "        if entity_type == 'B-LOC':\n",
    "            label = 'B-LOC'\n",
    "        elif entity_type == 'I-LOC':\n",
    "            label = 'I-LOC'\n",
    "        elif entity_type == 'B-ORG':\n",
    "            label = 'B-PRODUCT'\n",
    "        elif entity_type == 'I-ORG':\n",
    "            label = 'I-PRODUCT'\n",
    "        elif entity_type == 'B-MISC':\n",
    "            label = 'B-PRICE'\n",
    "        elif entity_type == 'I-MISC':\n",
    "            label = 'I-PRICE'\n",
    "        \n",
    "        # Apply NER labels to matching tokens\n",
    "        for i, token in enumerate(tokens):\n",
    "            if word in token:\n",
    "                labels[i] = label\n",
    "\n",
    "    return labels\n",
    "\n",
    "# Custom labeling function to identify prices and locations\n",
    "def custom_label_prices_locations(tokens):\n",
    "    labels = ['O'] * len(tokens)  # Initialize labels as 'O'\n",
    "    \n",
    "    # Define price patterns and location names\n",
    "    price_patterns = [r'^\\d*(00|.*50)(\\.\\d{1,2})?$', 'ETB', 'á‹‹áŒ‹', '\\$', 'á‰¥áˆ­', 'Birr']\n",
    "    \n",
    "    product_patterns=['sketchers', 'Nike', 'Adidas','Rebook','samsung','Samsung','Vans','Nikon', 'Nike','Puma',\n",
    "                      'Adidas','Lacosta', 'Rolex','New','Allstar','Vapor','Sketchers','FILA','CK','TRAZER',\n",
    "                      'Jordan','Womens','Human','Couple','Original','Victorias','BURBERRY','OFFER','Fila','2TB',\n",
    "                      'CLASICO','Men','Balenciaga','Shose','CASENT','NIKE','Nike','Airforce','ROLEX','LOUIS','CYBER',\n",
    "                      'Speed','speed','AIR','Air','Skacher','Time','All','Fitron','FITRON','EMPORIO','CK',\n",
    "                      'CHANEL','Skechers','Sketcher','NB','Old','old','OLD','FENDI','SPEED','BRAND','Brand',\n",
    "                      'BALENCIAGA','GUCCI','CHEKICH','GIORGIO','Jordan','JORDAN', 'Vest','European','Fur','VIGUER',\n",
    "                      'Quality', 'QUALITY','SVETSEON','Couple','COUPLE','High','HIGH','Under','ADIDAS','VANS','Sun',\n",
    "                      'Rolex','LEBRON','Lebron','Yezzy','ALEXANDER','XO','Jacket','55','HURACHE','Clark','Hermes','VM','RADO','Apple',\n",
    "                      'Fendi','Police','Champion','Gucci','Stan','Calvin','SWISH','SKMEL','FOR','Cr','Military','VEST','YEEZY','DIESEL','chekich']\n",
    "    \n",
    "    locations = ['Addis','Ababa', 'á‰¦áˆŒ', 'áˆœáŠ­áˆ²áŠ®', 'áˆˆá‰¡', 'Mekelle', 'Adama', 'Gondar', 'áˆˆá‰¡','áˆ˜á‹³áˆ…áŠ’á‹“áˆˆáˆ', \n",
    "                 'áˆ˜áŒˆáŠ“áŠ›', 'áŠ á‰ á‰£', 'áˆ€á‹­áˆá‰½','áŒ¦áˆ­', 'á‹µáˆªáˆ', 'á‰³á‹ˆáˆ­','205','áŠ á‹²áˆµ', 'á‰áŒ¥áˆ­', \"á‰¢áˆ®\", \"áá‰…\", \"2á‰°áŠ›\" ]\n",
    "    \n",
    "    # First, process the specific tokens you provided with custom labels\n",
    "    custom_tokens = {\n",
    "          \n",
    "        \"áŠ á‹µáˆ«áˆ»\"  : \"B-LOC\",       # Beginning of a location\n",
    "        \"Price\": \"B-PRICE\",         #Beginning of a price\n",
    "        \"Prices\": \"B-PRICE\",       #Beginning of a price\n",
    "        \"Free\" : \"O\",\n",
    "        \"Delivery\":\"O\",\n",
    "        \"Inbox\" :\"O\",\n",
    "        \"Hiwe5266\": \"O\",\n",
    "        \"áˆµáˆáŠ­\":\"O\",\n",
    "        \"á‹áˆ½áŠ•\":\"O\",\n",
    "        \"á‰°áˆ«\":\"O\",\n",
    "        \"Fashion\":\"O\",\n",
    "        \"Tera\":\"O\",\n",
    "        \"New\" : \"O\",\n",
    "        \"year\" :\"O\",\n",
    "        \"Discount\": \"O\",\n",
    "        \"me\" : \"O\",\n",
    "        \"httpsvmtiktokcomZM2yHbMPH\" : \"O\",\n",
    "        \"contact\" : \"O\",\n",
    "        \"sold\" : \"O\",\n",
    "        \"out\" : \"O\",\n",
    "        \"Sold\" : \"O\",\n",
    "        \"Call\" : \"O\",\n",
    "        \"call\" : \"O\",\n",
    "        \"more\" : \"O\",\n",
    "        \"info\" : \"O\",\n",
    "        \"as\" : \"O\",\n",
    "        \"Anyone\" : \"O\",\n",
    "        \"who\" : \"O\",\n",
    "        \"want\" : \"O\",\n",
    "        \"new\" : \"O\",\n",
    "        \"Original\" : \"O\",\n",
    "        \"BIG\" : \"O\",\n",
    "        \"DISCOUNT\" : \"O\",\n",
    "        \"á‰¥á‹›á‰µ\" : \"O\",\n",
    "        \"áˆˆáˆá‰µá‹ˆáˆµá‹±\" : \"O\",\n",
    "        \"áˆá‹©\" : \"O\",\n",
    "        \"á‰…áŠ“áˆ½\" : \"O\",\n",
    "        \"áŠ áˆˆá‹‰\" : \"O\",\n",
    "        \"á‰£áˆ‰á‰ á‰µ\" : \"O\",\n",
    "        \"áŠ¥áŠ“á‹°áˆ­áˆ³áˆˆáŠ•\" : \"O\",\n",
    "        \"áŒ«áˆ›\" : \"O\",\n",
    "        \"áˆˆáˆ˜áŒá‹›á‰µ\" : \"O\",\n",
    "        \"áˆ˜áˆ­áŠ«á‰¶\" : \"O\",\n",
    "        \"áŠ¥á‹¨áˆ„á‹±\" : \"O\",\n",
    "        \"á‹°áŠ­áˆ˜á‹‹áˆ\" : \"O\",\n",
    "        \"áŠ¥áŠ•áŒá‹²á‹«á‹áˆµ\" : \"O\",\n",
    "        \"á‰»áŠ“áˆ‹á‰½áŠ•áŠ•\" : \"O\",\n",
    "        \"á‰ áˆ˜á‰€áˆ‹á‰€áˆˆ\" : \"O\",\n",
    "        \"á‹¨áˆáˆˆáŒ‰á‰µáŠ•\" : \"O\",\n",
    "        \"á‹­á‹˜á‹™áŠ•\" : \"O\",\n",
    "        \"á‰£áˆ‰á‰ á‰µ\" : \"O\",\n",
    "        \"áŠ¥áŠ“áˆ˜áŒ£áˆˆáŠ•\" : \"O\",\n",
    "        \"httpstmejoinchatAAAAAEYRIOB5Tt7gKGGjA\" : \"O\",\n",
    "        \"Enkuan\": \"O\",\n",
    "        \"le\": \"O\",\n",
    "        \"berhan\": \"O\",\n",
    "        \"meswkelu\": \"O\",\n",
    "        \"beselam\": \"O\",\n",
    "        \"adersachu\": \"O\",\n",
    "               \n",
    "\n",
    "    }\n",
    " \n",
    "    # Apply labels based on the tokens\n",
    "    for i, token in enumerate(tokens):\n",
    "        # Check if token is in the custom list\n",
    "        if token in custom_tokens:\n",
    "            labels[i] = custom_tokens[token]\n",
    "        # Check if token matches very long numbers (10 digits or more)\n",
    "        elif re.match(r'^\\d{10,}$', token):\n",
    "            labels[i] = 'O'  # Label long numbers as 'O'\n",
    "        # Label prices (e.g., numbers, ETB, Birr, $, etc.)\n",
    "        elif any(pro in token for pro in product_patterns):\n",
    "            labels[i] = 'B-PRODUCT'\n",
    "        elif any(re.match(pattern, token) for pattern in price_patterns):\n",
    "            labels[i] = 'I-PRICE'\n",
    "        # Label locations (predefined locations)\n",
    "        elif any(loc in token for loc in locations):\n",
    "            labels[i] = 'I-LOC'\n",
    "        # Label other tokens as I-PRODUCT\n",
    "        else:\n",
    "            labels[i] = 'I-PRODUCT'\n",
    "    \n",
    "    return labels \n",
    "\n",
    "# Function to combine both NER and custom labels\n",
    "def combine_labels(ner_labels, custom_labels):\n",
    "    final_labels = []\n",
    "    \n",
    "    for ner_label, custom_label in zip(ner_labels, custom_labels):\n",
    "        if ner_label != 'O':  # NER label takes precedence\n",
    "            final_labels.append(ner_label)\n",
    "        else:\n",
    "            final_labels.append(custom_label)  # Otherwise, use custom label\n",
    "    \n",
    "    return final_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    }
   ],
   "source": [
    "# Function to process a message with both NER and custom methods\n",
    "def process_message(message, nlp_pipeline):\n",
    "    tokens = re.findall(r'\\S+', message)  # Tokenize the message\n",
    "    \n",
    "    # Apply NER model\n",
    "    ner_results = nlp_pipeline(message)\n",
    "    ner_labels = map_ner_to_conll(ner_results, tokens)\n",
    "    \n",
    "    # Apply custom labeling\n",
    "    custom_labels = custom_label_prices_locations(tokens)\n",
    "    \n",
    "    # Combine both label sets\n",
    "    final_labels = combine_labels(ner_labels, custom_labels)\n",
    "    \n",
    "    # Return tokens with their combined labels\n",
    "    labeled_tokens = [f\"{token} {label}\" for token, label in zip(tokens, final_labels)]\n",
    "    return \"\\n\".join(labeled_tokens)\n",
    "\n",
    "# Apply the combined processing to each message\n",
    "telegram_data['Labeled_Message'] = telegram_data['Message'].apply(lambda msg: process_message(msg, nlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel Username</th>\n",
       "      <th>ID</th>\n",
       "      <th>Message</th>\n",
       "      <th>Date</th>\n",
       "      <th>Labeled_Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>6211</td>\n",
       "      <td>INIMA JAPAN COFFEE GRINDER\\n\\náŠ¨áá‰°áŠ› áŒ¥áˆ«á‰µ \\n\\n150...</td>\n",
       "      <td>2025-01-17 06:59:57+00:00</td>\n",
       "      <td>INIMA I-PRODUCT\\nJAPAN I-PRODUCT\\nCOFFEE I-PRO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>6210</td>\n",
       "      <td>INIMA JAPAN COFFEE GRINDER\\n\\náŠ¨áá‰°áŠ› áŒ¥áˆ«á‰µ \\n\\n150...</td>\n",
       "      <td>2025-01-17 06:59:57+00:00</td>\n",
       "      <td>INIMA I-PRODUCT\\nJAPAN I-PRODUCT\\nCOFFEE I-PRO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>6207</td>\n",
       "      <td>stainless still flower shape cake mold\\n\\nnon ...</td>\n",
       "      <td>2025-01-16 13:41:31+00:00</td>\n",
       "      <td>stainless I-PRODUCT\\nstill I-PRODUCT\\nflower I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>6206</td>\n",
       "      <td>Delux Foldable multifunctional Draying RACK\\n\\...</td>\n",
       "      <td>2025-01-16 10:07:54+00:00</td>\n",
       "      <td>Delux I-PRODUCT\\nFoldable B-PRODUCT\\nmultifunc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>6205</td>\n",
       "      <td>áŠ áˆá‰†áˆáˆˆá‰°á‰£áˆ‹á‰½áˆá‰ á‹µáŒ‹áˆšáŠ áˆµáŒˆá‰¥á‰°áŠ“áˆ \\nAutomatic rotating noz...</td>\n",
       "      <td>2025-01-16 09:20:43+00:00</td>\n",
       "      <td>áŠ áˆá‰†áˆáˆˆá‰°á‰£áˆ‹á‰½áˆá‰ á‹µáŒ‹áˆšáŠ áˆµáŒˆá‰¥á‰°áŠ“áˆ I-LOC\\nAutomatic I-PRODU...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Channel Username    ID  \\\n",
       "0  @Shageronlinestore  6211   \n",
       "1  @Shageronlinestore  6210   \n",
       "2  @Shageronlinestore  6207   \n",
       "3  @Shageronlinestore  6206   \n",
       "4  @Shageronlinestore  6205   \n",
       "\n",
       "                                             Message  \\\n",
       "0  INIMA JAPAN COFFEE GRINDER\\n\\náŠ¨áá‰°áŠ› áŒ¥áˆ«á‰µ \\n\\n150...   \n",
       "1  INIMA JAPAN COFFEE GRINDER\\n\\náŠ¨áá‰°áŠ› áŒ¥áˆ«á‰µ \\n\\n150...   \n",
       "2  stainless still flower shape cake mold\\n\\nnon ...   \n",
       "3  Delux Foldable multifunctional Draying RACK\\n\\...   \n",
       "4  áŠ áˆá‰†áˆáˆˆá‰°á‰£áˆ‹á‰½áˆá‰ á‹µáŒ‹áˆšáŠ áˆµáŒˆá‰¥á‰°áŠ“áˆ \\nAutomatic rotating noz...   \n",
       "\n",
       "                        Date  \\\n",
       "0  2025-01-17 06:59:57+00:00   \n",
       "1  2025-01-17 06:59:57+00:00   \n",
       "2  2025-01-16 13:41:31+00:00   \n",
       "3  2025-01-16 10:07:54+00:00   \n",
       "4  2025-01-16 09:20:43+00:00   \n",
       "\n",
       "                                     Labeled_Message  \n",
       "0  INIMA I-PRODUCT\\nJAPAN I-PRODUCT\\nCOFFEE I-PRO...  \n",
       "1  INIMA I-PRODUCT\\nJAPAN I-PRODUCT\\nCOFFEE I-PRO...  \n",
       "2  stainless I-PRODUCT\\nstill I-PRODUCT\\nflower I...  \n",
       "3  Delux I-PRODUCT\\nFoldable B-PRODUCT\\nmultifunc...  \n",
       "4  áŠ áˆá‰†áˆáˆˆá‰°á‰£áˆ‹á‰½áˆá‰ á‹µáŒ‹áˆšáŠ áˆµáŒˆá‰¥á‰°áŠ“áˆ I-LOC\\nAutomatic I-PRODU...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telegram_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labeled data saved to C:\\Users\\fikad\\Desktop\\10acedamy\\EthioMart-NER-Named-Entity-Recognition-\\Data\\labeled_telegram_data_conll.conll\n"
     ]
    }
   ],
   "source": [
    "# Save the final labeled data to a CoNLL-style file\n",
    "output_file_combined = r'C:\\Users\\fikad\\Desktop\\10acedamy\\EthioMart-NER-Named-Entity-Recognition-\\Data\\labeled_telegram_data_conll.conll'\n",
    "with open(output_file_combined, 'w', encoding='utf-8') as f:\n",
    "    for index, row in telegram_data.iterrows():\n",
    "        f.write(f\"{row['Labeled_Message']}\\n\\n\")\n",
    "\n",
    "\n",
    "print(f\"labeled data saved to {output_file_combined}\")  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Week-5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
