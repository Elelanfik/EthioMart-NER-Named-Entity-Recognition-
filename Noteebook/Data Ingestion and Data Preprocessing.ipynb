{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìä Data Ingestion and Preprocessing for NER Model\n",
    "\n",
    "üéØ Objective\n",
    "\n",
    "Establish a data ingestion system to collect and preprocess messages from Ethiopian-based Telegram e-commerce channels for Named Entity Recognition (NER) tasks.\n",
    "\n",
    "üõ†Ô∏è Approach\n",
    "\n",
    "1Ô∏è‚É£ Data Ingestion\n",
    "\n",
    "- Channel Identification: Select at least five relevant Telegram channels focused on e-commerce.\n",
    "\n",
    "- Custom Scraper Development: Create a web scraper to automate the collection of messages, images, and documents from the identified channels.\n",
    "\n",
    "- Real-Time Data Collection: Implement a system to fetch data as it is posted, ensuring the dataset remains current.\n",
    "\n",
    "2Ô∏è‚É£ Data Preprocessing\n",
    "\n",
    "- Text Normalization: Clean the collected text by converting it to a consistent format (e.g., lowercasing, removing special characters).\n",
    "\n",
    "- Tokenization: Split the text into individual tokens (words) for easier analysis.\n",
    "\n",
    "- Handling Amharic-Specific Features: Address unique linguistic characteristics of the Amharic language, such as diacritics and script variations.\n",
    "\n",
    "3Ô∏è‚É£ Data Structuring\n",
    "\n",
    "- Metadata Separation: Organize the data by separating metadata (e.g., sender, timestamp) from the message content.\n",
    "\n",
    "- Unified Format Creation: Structure the cleaned data into a consistent format (e.g., CSV, JSON) for further analysis.\n",
    "\n",
    "4Ô∏è‚É£ Quality Assurance\n",
    "\n",
    "- Data Review: Conduct a thorough review of the collected data to ensure completeness and accuracy, checking for any missing or corrupted entries.\n",
    "\n",
    "5Ô∏è‚É£ Data Storage\n",
    "\n",
    "- Save Preprocessed Data: Store the cleaned and structured data in a suitable format for easy access during the labeling and model training phases.\n",
    "\n",
    "‚úÖ Summary of Steps\n",
    "\n",
    "1. Identify relevant Telegram channels.\n",
    "\n",
    "2. Develop a custom scraper for data collection.\n",
    "\n",
    "3. Preprocess the collected data.\n",
    "\n",
    "4. Structure and organize the data.\n",
    "\n",
    "5. Conduct quality assurance and store the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "    h1 {\n",
    "        color: #ffaa00;\n",
    "        text-shadow: 2px 2px 5px #000;\n",
    "        font-family: \"Comic Sans MS\", sans-serif;\n",
    "    }\n",
    "</style>\n",
    "\n",
    "<h1>‚ú® Logging Setup Example in Python ‚ú®</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "    h1 {\n",
    "        color: #ffaa00;\n",
    "        text-shadow: 2px 2px 5px #000;\n",
    "        font-family: \"Comic Sans MS\", sans-serif;\n",
    "    }\n",
    "</style>\n",
    "\n",
    "<h1>‚ú® Importing Modules ‚ú®</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "notebook_dir = os.getcwd()\n",
    "sys.path.append(os.path.abspath(os.path.join(notebook_dir, '..')))\n",
    "sys.path.append(os.path.abspath('../scripts'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.analysis import extract_messages_from_html_files, load_csv_to_dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "    h1 {\n",
    "        color: #ffaa00;\n",
    "        text-shadow: 2px 2px 5px #000;\n",
    "        font-family: \"Comic Sans MS\", sans-serif;\n",
    "    }\n",
    "</style>\n",
    "\n",
    "<h1>‚ú® Loading Extracting Messages from telegram in CSV form‚ú®</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Channel Username    ID  \\\n",
      "0  @Shageronlinestore  6211   \n",
      "1  @Shageronlinestore  6210   \n",
      "2  @Shageronlinestore  6207   \n",
      "3  @Shageronlinestore  6206   \n",
      "4  @Shageronlinestore  6205   \n",
      "\n",
      "                                             Message  \\\n",
      "0  üí•INIMA JAPAN COFFEE GRINDER\\n\\nüíØ·ä®·çç·â∞·äõ ·å•·à´·âµ \\n\\n‚ö°...   \n",
      "1  üí•INIMA JAPAN COFFEE GRINDER\\n\\nüíØ·ä®·çç·â∞·äõ ·å•·à´·âµ \\n\\n‚ö°...   \n",
      "2  üí•stainless still flower shape cake mold\\n\\n‚ö°Ô∏èn...   \n",
      "3  üí•Delux Foldable multifunctional Draying RACK\\n...   \n",
      "4  #·ä†·àç·âÜ·àç_·àà·â∞·â£·àã·âΩ·àÅ_·â†·ãµ·åã·àö_·ä†·àµ·åà·â•·â∞·äì·àç \\nüí•Automatic rotatin...   \n",
      "\n",
      "                        Date  \n",
      "0  2025-01-17 06:59:57+00:00  \n",
      "1  2025-01-17 06:59:57+00:00  \n",
      "2  2025-01-16 13:41:31+00:00  \n",
      "3  2025-01-16 10:07:54+00:00  \n",
      "4  2025-01-16 09:20:43+00:00  \n"
     ]
    }
   ],
   "source": [
    "# Load the CSV into a pandas DataFrame\n",
    "telegram_data = load_csv_to_dataframe(r\"C:\\Users\\fikad\\Desktop\\10acedamy\\EthioMart-NER-Named-Entity-Recognition-\\Data\\telegram_data.csv\")\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(telegram_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "    h3 {\n",
    "        color: #ff1199;\n",
    "        text-shadow: 2px 2px 5px #000;\n",
    "        font-family: \"Comic Sans MS\", sans-serif;\n",
    "    }\n",
    "</style>\n",
    "\n",
    "<h3>‚ú® checking NAN and cleaning it‚ú®</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel Username</th>\n",
       "      <th>ID</th>\n",
       "      <th>Message</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>6211</td>\n",
       "      <td>üí•INIMA JAPAN COFFEE GRINDER\\n\\nüíØ·ä®·çç·â∞·äõ ·å•·à´·âµ \\n\\n‚ö°...</td>\n",
       "      <td>2025-01-17 06:59:57+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>6210</td>\n",
       "      <td>üí•INIMA JAPAN COFFEE GRINDER\\n\\nüíØ·ä®·çç·â∞·äõ ·å•·à´·âµ \\n\\n‚ö°...</td>\n",
       "      <td>2025-01-17 06:59:57+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>6207</td>\n",
       "      <td>üí•stainless still flower shape cake mold\\n\\n‚ö°Ô∏èn...</td>\n",
       "      <td>2025-01-16 13:41:31+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>6206</td>\n",
       "      <td>üí•Delux Foldable multifunctional Draying RACK\\n...</td>\n",
       "      <td>2025-01-16 10:07:54+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>6205</td>\n",
       "      <td>#·ä†·àç·âÜ·àç_·àà·â∞·â£·àã·âΩ·àÅ_·â†·ãµ·åã·àö_·ä†·àµ·åà·â•·â∞·äì·àç \\nüí•Automatic rotatin...</td>\n",
       "      <td>2025-01-16 09:20:43+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>@helloomarketethiopia</td>\n",
       "      <td>4210</td>\n",
       "      <td>·ä•·äï·ä≥·äï ·àà·ä†·ã≤·à± ·ãì·àò·âµ ·â†·à∞·àã·àù ·ä†·ã∞·à®·à≥·âΩ·àÅ!\\n·ã®·àç·åÜ·âΩ ·ã®·äï·â£·â• ·ä•·äï·ã≤·àÅ·àù ·ã®·âÄ...</td>\n",
       "      <td>2024-09-18 14:39:51+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>@helloomarketethiopia</td>\n",
       "      <td>4209</td>\n",
       "      <td>·ä•·äï·ä≥·äï ·àà·ä†·ã≤·à± ·ãì·àò·âµ ·â†·à∞·àã·àù ·ä†·ã∞·à®·à≥·âΩ·àÅ!\\n·àà·çÄ·åâ·à≠·ãé ·àç·àµ·àã·à≥·à¥·ç° ·å†·äï·ä´·à¨ ...</td>\n",
       "      <td>2024-09-18 09:05:51+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>@helloomarketethiopia</td>\n",
       "      <td>4208</td>\n",
       "      <td>·ä•·äï·ä≥·äï ·àà·ä†·ã≤·à± ·ãì·àò·âµ ·â†·à∞·àã·àù ·ä†·ã∞·à®·à≥·âΩ·àÅ!\\n·àà·àÅ·àà·â±·àù ·çÜ·â≥ ·ã®·àö·àÜ·äï ·â†·åÄ·à≠·â£...</td>\n",
       "      <td>2024-09-17 18:00:11+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>@helloomarketethiopia</td>\n",
       "      <td>4207</td>\n",
       "      <td>·ä•·äï·ä≥·äï ·àà·ä†·ã≤·à± ·ãì·àò·âµ ·â†·à∞·àã·àù ·ä†·ã∞·à®·à≥·âΩ·àÅ!\\n·ä®·à∏·à´ ·ã®·â∞·à∞·à´ ·ã®·àç·åÜ·âΩ ·ã®·àù·à≥·ä•...</td>\n",
       "      <td>2024-09-17 15:18:21+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>@helloomarketethiopia</td>\n",
       "      <td>4206</td>\n",
       "      <td>·ä•·äï·ä≥·äï ·àà·ä†·ã≤·à± ·ãì·àò·âµ ·â†·à∞·àã·àù ·ä†·ã∞·à®·à≥·âΩ·àÅ!\\n·ä•·äï·ã≤·àÖ ·ãµ·àù·âÖ ·ã´·àà ·â£·àÖ·àã·ãä ·ã®...</td>\n",
       "      <td>2024-09-16 14:40:20+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Channel Username    ID  \\\n",
       "0       @Shageronlinestore  6211   \n",
       "1       @Shageronlinestore  6210   \n",
       "2       @Shageronlinestore  6207   \n",
       "3       @Shageronlinestore  6206   \n",
       "4       @Shageronlinestore  6205   \n",
       "..                     ...   ...   \n",
       "995  @helloomarketethiopia  4210   \n",
       "996  @helloomarketethiopia  4209   \n",
       "997  @helloomarketethiopia  4208   \n",
       "998  @helloomarketethiopia  4207   \n",
       "999  @helloomarketethiopia  4206   \n",
       "\n",
       "                                               Message  \\\n",
       "0    üí•INIMA JAPAN COFFEE GRINDER\\n\\nüíØ·ä®·çç·â∞·äõ ·å•·à´·âµ \\n\\n‚ö°...   \n",
       "1    üí•INIMA JAPAN COFFEE GRINDER\\n\\nüíØ·ä®·çç·â∞·äõ ·å•·à´·âµ \\n\\n‚ö°...   \n",
       "2    üí•stainless still flower shape cake mold\\n\\n‚ö°Ô∏èn...   \n",
       "3    üí•Delux Foldable multifunctional Draying RACK\\n...   \n",
       "4    #·ä†·àç·âÜ·àç_·àà·â∞·â£·àã·âΩ·àÅ_·â†·ãµ·åã·àö_·ä†·àµ·åà·â•·â∞·äì·àç \\nüí•Automatic rotatin...   \n",
       "..                                                 ...   \n",
       "995  ·ä•·äï·ä≥·äï ·àà·ä†·ã≤·à± ·ãì·àò·âµ ·â†·à∞·àã·àù ·ä†·ã∞·à®·à≥·âΩ·àÅ!\\n·ã®·àç·åÜ·âΩ ·ã®·äï·â£·â• ·ä•·äï·ã≤·àÅ·àù ·ã®·âÄ...   \n",
       "996  ·ä•·äï·ä≥·äï ·àà·ä†·ã≤·à± ·ãì·àò·âµ ·â†·à∞·àã·àù ·ä†·ã∞·à®·à≥·âΩ·àÅ!\\n·àà·çÄ·åâ·à≠·ãé ·àç·àµ·àã·à≥·à¥·ç° ·å†·äï·ä´·à¨ ...   \n",
       "997  ·ä•·äï·ä≥·äï ·àà·ä†·ã≤·à± ·ãì·àò·âµ ·â†·à∞·àã·àù ·ä†·ã∞·à®·à≥·âΩ·àÅ!\\n·àà·àÅ·àà·â±·àù ·çÜ·â≥ ·ã®·àö·àÜ·äï ·â†·åÄ·à≠·â£...   \n",
       "998  ·ä•·äï·ä≥·äï ·àà·ä†·ã≤·à± ·ãì·àò·âµ ·â†·à∞·àã·àù ·ä†·ã∞·à®·à≥·âΩ·àÅ!\\n·ä®·à∏·à´ ·ã®·â∞·à∞·à´ ·ã®·àç·åÜ·âΩ ·ã®·àù·à≥·ä•...   \n",
       "999  ·ä•·äï·ä≥·äï ·àà·ä†·ã≤·à± ·ãì·àò·âµ ·â†·à∞·àã·àù ·ä†·ã∞·à®·à≥·âΩ·àÅ!\\n·ä•·äï·ã≤·àÖ ·ãµ·àù·âÖ ·ã´·àà ·â£·àÖ·àã·ãä ·ã®...   \n",
       "\n",
       "                          Date  \n",
       "0    2025-01-17 06:59:57+00:00  \n",
       "1    2025-01-17 06:59:57+00:00  \n",
       "2    2025-01-16 13:41:31+00:00  \n",
       "3    2025-01-16 10:07:54+00:00  \n",
       "4    2025-01-16 09:20:43+00:00  \n",
       "..                         ...  \n",
       "995  2024-09-18 14:39:51+00:00  \n",
       "996  2024-09-18 09:05:51+00:00  \n",
       "997  2024-09-17 18:00:11+00:00  \n",
       "998  2024-09-17 15:18:21+00:00  \n",
       "999  2024-09-16 14:40:20+00:00  \n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telegram_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for NaN values in the 'Message' column:\n",
      "Number of NaN values in 'Message' column: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Checking for NaN values in the 'Message' column:\")\n",
    "nan_count = telegram_data['Message'].isnull().sum()\n",
    "print(f\"Number of NaN values in 'Message' column: {nan_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      üí•INIMA JAPAN COFFEE GRINDER\\n\\nüíØ·ä®·çç·â∞·äõ ·å•·à´·âµ \\n\\n‚ö°...\n",
       "1      üí•INIMA JAPAN COFFEE GRINDER\\n\\nüíØ·ä®·çç·â∞·äõ ·å•·à´·âµ \\n\\n‚ö°...\n",
       "2      üí•stainless still flower shape cake mold\\n\\n‚ö°Ô∏èn...\n",
       "3      üí•Delux Foldable multifunctional Draying RACK\\n...\n",
       "4      #·ä†·àç·âÜ·àç_·àà·â∞·â£·àã·âΩ·àÅ_·â†·ãµ·åã·àö_·ä†·àµ·åà·â•·â∞·äì·àç \\nüí•Automatic rotatin...\n",
       "                             ...                        \n",
       "995    ·ä•·äï·ä≥·äï ·àà·ä†·ã≤·à± ·ãì·àò·âµ ·â†·à∞·àã·àù ·ä†·ã∞·à®·à≥·âΩ·àÅ!\\n·ã®·àç·åÜ·âΩ ·ã®·äï·â£·â• ·ä•·äï·ã≤·àÅ·àù ·ã®·âÄ...\n",
       "996    ·ä•·äï·ä≥·äï ·àà·ä†·ã≤·à± ·ãì·àò·âµ ·â†·à∞·àã·àù ·ä†·ã∞·à®·à≥·âΩ·àÅ!\\n·àà·çÄ·åâ·à≠·ãé ·àç·àµ·àã·à≥·à¥·ç° ·å†·äï·ä´·à¨ ...\n",
       "997    ·ä•·äï·ä≥·äï ·àà·ä†·ã≤·à± ·ãì·àò·âµ ·â†·à∞·àã·àù ·ä†·ã∞·à®·à≥·âΩ·àÅ!\\n·àà·àÅ·àà·â±·àù ·çÜ·â≥ ·ã®·àö·àÜ·äï ·â†·åÄ·à≠·â£...\n",
       "998    ·ä•·äï·ä≥·äï ·àà·ä†·ã≤·à± ·ãì·àò·âµ ·â†·à∞·àã·àù ·ä†·ã∞·à®·à≥·âΩ·àÅ!\\n·ä®·à∏·à´ ·ã®·â∞·à∞·à´ ·ã®·àç·åÜ·âΩ ·ã®·àù·à≥·ä•...\n",
       "999    ·ä•·äï·ä≥·äï ·àà·ä†·ã≤·à± ·ãì·àò·âµ ·â†·à∞·àã·àù ·ä†·ã∞·à®·à≥·âΩ·àÅ!\\n·ä•·äï·ã≤·àÖ ·ãµ·àù·âÖ ·ã´·àà ·â£·àÖ·àã·ãä ·ã®...\n",
       "Name: Message, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telegram_data_df=telegram_data['Message']\n",
    "telegram_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "    h2 {\n",
    "        color: #ffaa00;\n",
    "        text-shadow: 2px 2px 5px #000;\n",
    "        font-family: \"Comic Sans MS\", sans-serif;\n",
    "    }\n",
    "</style>\n",
    "\n",
    "<h2>‚ú®   Extracting Unique Characters from a CSV Column ‚ú®</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique characters found:\n",
      "['\\n', ' ', '!', '\"', '#', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '=', '>', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '|', '~', '\\xa0', '¬Æ', '¬∞', '√ó', '·àÄ', '·àÅ', '·àÇ', '·àÉ', '·àÑ', '·àÖ', '·àÜ', '·àà', '·àâ', '·àä', '·àã', '·àå', '·àç', '·àé', '·àê', '·àí', '·àï', '·àò', '·àô', '·àö', '·àõ', '·àú', '·àù', '·àû', '·àü', '·à†', '·à£', '·à®', '·à©', '·à™', '·à´', '·à¨', '·à≠', '·àÆ', '·àØ', '·à∞', '·à±', '·à≤', '·à≥', '·à¥', '·àµ', '·à∂', '·à∏', '·àπ', '·àª', '·àº', '·àΩ', '·àæ', '·âÄ', '·âÅ', '·âÇ', '·âÉ', '·âÑ', '·âÖ', '·âÜ', '·âã', '·â†', '·â°', '·â¢', '·â£', '·â§', '·â•', '·â¶', '·âß', '·â®', '·â™', '·â´', '·â≠', '·âÆ', '·â∞', '·â±', '·â≤', '·â≥', '·â¥', '·âµ', '·â∂', '·â∑', '·â∏', '·âπ', '·â∫', '·âª', '·âº', '·âΩ', '·âæ', '·äã', '·äê', '·äë', '·äí', '·äì', '·äî', '·äï', '·äñ', '·äò', '·äô', '·äõ', '·äù', '·äû', '·ä†', '·ä¢', '·ä£', '·ä§', '·ä•', '·ä¶', '·ä®', '·ä©', '·ä™', '·ä´', '·ä¨', '·ä≠', '·äÆ', '·ä≥', '·ãà', '·ãâ', '·ãä', '·ãã', '·ãå', '·ãç', '·ãé', '·ãí', '·ãì', '·ãï', '·ãò', '·ãô', '·ãö', '·ãõ', '·ãú', '·ãù', '·ãû', '·ãü', '·ã¢', '·ã£', '·ã®', '·ã©', '·ã™', '·ã´', '·ã¨', '·ã≠', '·ãÆ', '·ã∞', '·ã±', '·ã≤', '·ã≥', '·ã¥', '·ãµ', '·ã∂', '·åÄ', '·åÅ', '·åÇ', '·åÉ', '·åÖ', '·åÜ', '·åá', '·åà', '·åâ', '·åä', '·åã', '·åå', '·åç', '·åé', '·åê', '·åì', '·å†', '·å°', '·å¢', '·å£', '·å§', '·å•', '·å¶', '·åß', '·å®', '·å©', '·å™', '·å´', '·å≠', '·åÆ', '·åØ', '·å¥', '·åµ', '·å∏', '·åª', '·åΩ', '·çÄ', '·çÅ', '·çÇ', '·çÉ', '·çÖ', '·çÜ', '·çà', '·çâ', '·çä', '·çã', '·çå', '·çç', '·çé', '·çè', '·çê', '·çí', '·çì', '·çî', '·çï', '·çñ', '·ç°', '·ç¢', '·ç£', '·ç§', '·ç•', '·ç¶', '‚Äî', '‚Äô', '‚Äú', '‚Äù', '‚Ä¢', '‚Ä≥', '‚Äº', '‚É£', '‚Ñ¢', '‚è∞', '‚è≤', '‚óè', '‚òÑ', '‚òé', '‚òë', '‚òï', '‚ô•', '‚ô¶', '‚ö†', '‚ö°', '‚úÖ', '‚úç', '‚úî', '‚úñ', '‚ú®', '‚ùá', '‚ùå', '‚ùì', '‚ùó', '‚ù§', '‚û°', '‚§µ', '‚≠ê', 'Ô∏é', 'Ô∏è', 'ùóî', 'ùóï', 'ùóñ', 'ùóó', 'ùóò', 'ùóô', 'ùóö', 'ùóú', 'ùóü', 'ùó°', 'ùó¢', 'ùó£', 'ùó•', 'ùó¶', 'ùó©', 'ùó™', 'ùó∞', 'ùó±', 'ùó≤', 'ùóµ', 'ùó∂', 'ùóπ', 'ùóª', 'ùóº', 'ùóΩ', 'ùóø', 'ùòÄ', 'ùòÅ', 'ùòÇ', 'ùòÑ', 'ùôó', 'ùô£', 'ùô§', 'ùô≠', 'üÖê', 'üÖë', 'üÖí', 'üÖì', 'üÖî', 'üÖñ', 'üÖó', 'üÖò', 'üÖõ', 'üÖú', 'üÖù', 'üÖû', 'üÖü', 'üÖ°', 'üÖ¢', 'üÖ£', 'üÖ§', 'üÖ•', 'üÖ®', 'üÖ∞', 'üÜï', 'üá™', 'üá∑', 'üá∏', 'üáπ', 'üá∫', 'üåê', 'üåû', 'üåü', 'üåÆ', 'üå≤', 'üåª', 'üçÄ', 'üçï', 'üçñ', 'üçó', 'üçü', 'üç∏', 'üçº', 'üçΩ', 'üçæ', 'üéÅ', 'üéÑ', 'üéÜ', 'üé•', 'üé©', 'üéØ', 'üè¢', 'üè∑', 'üèΩ', 'üèæ', 'üêÄ', 'üêõ', 'üëÄ', 'üëá', 'üëà', 'üëâ', 'üëã', 'üëå', 'üëç', 'üëè', 'üëî', 'üëü', 'üë†', 'üë∏', 'üíÖ', 'üíä', 'üí•', 'üí¶', 'üíß', 'üí™', 'üí´', 'üí¨', 'üíØ', 'üí∞', 'üí≤', 'üí¥', 'üíµ', 'üíª', 'üìÉ', 'üìà', 'üìå', 'üìç', 'üìô', 'üìû', 'üì£', 'üì©', 'üì±', 'üì≤', 'üîÑ', 'üîî', 'üîñ', 'üîò', 'üî†', 'üî§', 'üî•', 'üî∞', 'üî¥', 'üîº', 'üîΩ', 'üï∑', 'üñå', 'üñ•', 'üóÑ', 'üóì', 'üóØ', 'üòÄ', 'üòç', 'üòé', 'üòè', 'üòÆ', 'üò±', 'üò≤', 'üò≥', 'üôà', 'üöõ', 'üö©', 'üõÅ', 'üõç', 'üõí', 'üõ°', 'üü†', 'üü¢', 'ü§û', 'ü§®', 'ü§´', 'ü•ì', 'ü•õ', 'ü•û', 'ü•ü', 'ü•ß', 'ü•©', 'ü•Æ', 'ü•µ', 'ü¶ó', 'ü¶ü', 'üßÜ', 'üßä', 'ü™û', 'ü™∞', 'ü™≥', 'ü´ì', 'ü´ï']\n"
     ]
    }
   ],
   "source": [
    "# Combine all rows in the 'Address' column into a single string\n",
    "combined_text = \" \".join(telegram_data[\"Message\"].astype(str))\n",
    "\n",
    "# Find unique characters\n",
    "unique_chars = sorted(set(combined_text))\n",
    "\n",
    "# Print the unique characters\n",
    "print(\"Unique characters found:\")\n",
    "print(unique_chars)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "    h3 {\n",
    "        color: #ff1199;\n",
    "        text-shadow: 2px 2px 5px #000;\n",
    "        font-family: \"Comic Sans MS\", sans-serif;\n",
    "    }\n",
    "</style>\n",
    "\n",
    "<h3>‚ú®   Extracting Unique Characters from a CSV Column ‚ú®</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel Username</th>\n",
       "      <th>ID</th>\n",
       "      <th>Message</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>6211</td>\n",
       "      <td>INIMA JAPAN COFFEE GRINDER\\n\\n·ä®·çç·â∞·äõ ·å•·à´·âµ \\n\\n150...</td>\n",
       "      <td>2025-01-17 06:59:57+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>6210</td>\n",
       "      <td>INIMA JAPAN COFFEE GRINDER\\n\\n·ä®·çç·â∞·äõ ·å•·à´·âµ \\n\\n150...</td>\n",
       "      <td>2025-01-17 06:59:57+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>6207</td>\n",
       "      <td>stainless still flower shape cake mold\\n\\nnon ...</td>\n",
       "      <td>2025-01-16 13:41:31+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>6206</td>\n",
       "      <td>Delux Foldable multifunctional Draying RACK\\n\\...</td>\n",
       "      <td>2025-01-16 10:07:54+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>6205</td>\n",
       "      <td>·ä†·àç·âÜ·àç·àà·â∞·â£·àã·âΩ·àÅ·â†·ãµ·åã·àö·ä†·àµ·åà·â•·â∞·äì·àç \\nAutomatic rotating noz...</td>\n",
       "      <td>2025-01-16 09:20:43+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Channel Username    ID  \\\n",
       "0  @Shageronlinestore  6211   \n",
       "1  @Shageronlinestore  6210   \n",
       "2  @Shageronlinestore  6207   \n",
       "3  @Shageronlinestore  6206   \n",
       "4  @Shageronlinestore  6205   \n",
       "\n",
       "                                             Message  \\\n",
       "0  INIMA JAPAN COFFEE GRINDER\\n\\n·ä®·çç·â∞·äõ ·å•·à´·âµ \\n\\n150...   \n",
       "1  INIMA JAPAN COFFEE GRINDER\\n\\n·ä®·çç·â∞·äõ ·å•·à´·âµ \\n\\n150...   \n",
       "2  stainless still flower shape cake mold\\n\\nnon ...   \n",
       "3  Delux Foldable multifunctional Draying RACK\\n\\...   \n",
       "4  ·ä†·àç·âÜ·àç·àà·â∞·â£·àã·âΩ·àÅ·â†·ãµ·åã·àö·ä†·àµ·åà·â•·â∞·äì·àç \\nAutomatic rotating noz...   \n",
       "\n",
       "                        Date  \n",
       "0  2025-01-17 06:59:57+00:00  \n",
       "1  2025-01-17 06:59:57+00:00  \n",
       "2  2025-01-16 13:41:31+00:00  \n",
       "3  2025-01-16 10:07:54+00:00  \n",
       "4  2025-01-16 09:20:43+00:00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import emoji\n",
    "import re\n",
    "\n",
    "\n",
    "# Function to clean the text (remove emojis, symbols, etc.)\n",
    "def remove_emoji(text):\n",
    "    if isinstance(text, str):\n",
    "        return emoji.replace_emoji(text, replace='')\n",
    "    return text\n",
    "\n",
    "def remove_symbols(text):\n",
    "    if isinstance(text, str):\n",
    "        return re.sub(r'[^A-Za-z0-9·àÄ-·çê\\s]+', '', text)\n",
    "    return text\n",
    "\n",
    "# Apply cleaning functions to 'Message' column\n",
    "telegram_data['Message'] = telegram_data['Message'].apply(remove_emoji).apply(remove_symbols)\n",
    "display(telegram_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "    h1 {\n",
    "        color: #ffaa00;\n",
    "        text-shadow: 2px 2px 5px #000;\n",
    "        font-family: \"Comic Sans MS\", sans-serif;\n",
    "    }\n",
    "</style>\n",
    "\n",
    "<h1>‚ú®    Named Entity Recognition (NER) Labeling Function‚ú®</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fikad\\Desktop\\10acedamy\\EthioMart-NER-Named-Entity-Recognition-\\Week-5\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline \n",
    "#Load the tokenizer and model for NER\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mbeukman/xlm-roberta-base-finetuned-amharic-finetuned-ner-amharic\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"mbeukman/xlm-roberta-base-finetuned-amharic-finetuned-ner-amharic\")\n",
    "\n",
    "# Set up NER pipeline\n",
    "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to map NER model results to CoNLL format labels\n",
    "def map_ner_to_conll(ner_results, tokens):\n",
    "    labels = ['O'] * len(tokens)  # Initialize labels as 'O' (Outside)\n",
    "    \n",
    "    for entity in ner_results:\n",
    "        word = entity['word'].replace('##', '')  # Remove subword artifacts from NER results\n",
    "        entity_type = entity['entity']  # Extract entity type\n",
    "        \n",
    "        # Define mapping for NER entity types\n",
    "        label = 'O'  # Default label\n",
    "        if entity_type == 'B-LOC':\n",
    "            label = 'B-LOC'\n",
    "        elif entity_type == 'I-LOC':\n",
    "            label = 'I-LOC'\n",
    "        elif entity_type == 'B-ORG':\n",
    "            label = 'B-PRODUCT'\n",
    "        elif entity_type == 'I-ORG':\n",
    "            label = 'I-PRODUCT'\n",
    "        elif entity_type == 'B-MISC':\n",
    "            label = 'B-PRICE'\n",
    "        elif entity_type == 'I-MISC':\n",
    "            label = 'I-PRICE'\n",
    "        \n",
    "        # Apply NER labels to matching tokens\n",
    "        for i, token in enumerate(tokens):\n",
    "            if word in token:\n",
    "                labels[i] = label\n",
    "\n",
    "    return labels\n",
    "\n",
    "# Custom labeling function to identify prices and locations\n",
    "def custom_label_prices_locations(tokens):\n",
    "    labels = ['O'] * len(tokens)  # Initialize labels as 'O'\n",
    "    \n",
    "    # Define price patterns and location names\n",
    "    price_patterns = [r'^\\d*(00|.*50)(\\.\\d{1,2})?$', 'ETB', '·ãã·åã', '\\$', '·â•·à≠', 'Birr']\n",
    "    \n",
    "    product_patterns=['sketchers', 'Nike', 'Adidas','Rebook','samsung','Samsung','Vans','Nikon', 'Nike','Puma',\n",
    "                      'Adidas','Lacosta', 'Rolex','New','Allstar','Vapor','Sketchers','FILA','CK','TRAZER',\n",
    "                      'Jordan','Womens','Human','Couple','Original','Victorias','BURBERRY','OFFER','Fila','2TB',\n",
    "                      'CLASICO','Men','Balenciaga','Shose','CASENT','NIKE','Nike','Airforce','ROLEX','LOUIS','CYBER',\n",
    "                      'Speed','speed','AIR','Air','Skacher','Time','All','Fitron','FITRON','EMPORIO','CK',\n",
    "                      'CHANEL','Skechers','Sketcher','NB','Old','old','OLD','FENDI','SPEED','BRAND','Brand',\n",
    "                      'BALENCIAGA','GUCCI','CHEKICH','GIORGIO','Jordan','JORDAN', 'Vest','European','Fur','VIGUER',\n",
    "                      'Quality', 'QUALITY','SVETSEON','Couple','COUPLE','High','HIGH','Under','ADIDAS','VANS','Sun',\n",
    "                      'Rolex','LEBRON','Lebron','Yezzy','ALEXANDER','XO','Jacket','55','HURACHE','Clark','Hermes','VM','RADO','Apple',\n",
    "                      'Fendi','Police','Champion','Gucci','Stan','Calvin','SWISH','SKMEL','FOR','Cr','Military','VEST','YEEZY','DIESEL','chekich']\n",
    "    \n",
    "    locations = ['Addis','Ababa', '·â¶·àå', '·àú·ä≠·à≤·äÆ', '·àà·â°', 'Mekelle', 'Adama', 'Gondar', '·àà·â°','·àò·ã≥·àÖ·äí·ãì·àà·àù', \n",
    "                 '·àò·åà·äì·äõ', '·ä†·â†·â£', '·àÄ·ã≠·àé·âΩ','·å¶·à≠', '·ãµ·à™·àù', '·â≥·ãà·à≠','205','·ä†·ã≤·àµ', '·âÅ·å•·à≠', \"·â¢·àÆ\", \"·çé·âÖ\", \"2·â∞·äõ\" ]\n",
    "    \n",
    "    # First, process the specific tokens you provided with custom labels\n",
    "    custom_tokens = {\n",
    "          \n",
    "        \"·ä†·ãµ·à´·àª\"  : \"B-LOC\",       # Beginning of a location\n",
    "        \"Price\": \"B-PRICE\",         #Beginning of a price\n",
    "        \"Prices\": \"B-PRICE\",       #Beginning of a price\n",
    "        \"Free\" : \"O\",\n",
    "        \"Delivery\":\"O\",\n",
    "        \"Inbox\" :\"O\",\n",
    "        \"Hiwe5266\": \"O\",\n",
    "        \"·àµ·àç·ä≠\":\"O\",\n",
    "        \"·çã·àΩ·äï\":\"O\",\n",
    "        \"·â∞·à´\":\"O\",\n",
    "        \"Fashion\":\"O\",\n",
    "        \"Tera\":\"O\",\n",
    "        \"New\" : \"O\",\n",
    "        \"year\" :\"O\",\n",
    "        \"Discount\": \"O\",\n",
    "        \"me\" : \"O\",\n",
    "        \"httpsvmtiktokcomZM2yHbMPH\" : \"O\",\n",
    "        \"contact\" : \"O\",\n",
    "        \"sold\" : \"O\",\n",
    "        \"out\" : \"O\",\n",
    "        \"Sold\" : \"O\",\n",
    "        \"Call\" : \"O\",\n",
    "        \"call\" : \"O\",\n",
    "        \"more\" : \"O\",\n",
    "        \"info\" : \"O\",\n",
    "        \"as\" : \"O\",\n",
    "        \"Anyone\" : \"O\",\n",
    "        \"who\" : \"O\",\n",
    "        \"want\" : \"O\",\n",
    "        \"new\" : \"O\",\n",
    "        \"Original\" : \"O\",\n",
    "        \"BIG\" : \"O\",\n",
    "        \"DISCOUNT\" : \"O\",\n",
    "        \"·â•·ãõ·âµ\" : \"O\",\n",
    "        \"·àà·àù·âµ·ãà·àµ·ã±\" : \"O\",\n",
    "        \"·àç·ã©\" : \"O\",\n",
    "        \"·âÖ·äì·àΩ\" : \"O\",\n",
    "        \"·ä†·àà·ãâ\" : \"O\",\n",
    "        \"·â£·àâ·â†·âµ\" : \"O\",\n",
    "        \"·ä•·äì·ã∞·à≠·à≥·àà·äï\" : \"O\",\n",
    "        \"·å´·àõ\" : \"O\",\n",
    "        \"·àà·àò·åç·ãõ·âµ\" : \"O\",\n",
    "        \"·àò·à≠·ä´·â∂\" : \"O\",\n",
    "        \"·ä•·ã®·àÑ·ã±\" : \"O\",\n",
    "        \"·ã∞·ä≠·àò·ãã·àç\" : \"O\",\n",
    "        \"·ä•·äï·åç·ã≤·ã´·ãç·àµ\" : \"O\",\n",
    "        \"·âª·äì·àã·âΩ·äï·äï\" : \"O\",\n",
    "        \"·â†·àò·âÄ·àã·âÄ·àà\" : \"O\",\n",
    "        \"·ã®·çà·àà·åâ·âµ·äï\" : \"O\",\n",
    "        \"·ã≠·ãò·ãô·äï\" : \"O\",\n",
    "        \"·â£·àâ·â†·âµ\" : \"O\",\n",
    "        \"·ä•·äì·àò·å£·àà·äï\" : \"O\",\n",
    "        \"httpstmejoinchatAAAAAEYRIOB5Tt7gKGGjA\" : \"O\",\n",
    "        \"Enkuan\": \"O\",\n",
    "        \"le\": \"O\",\n",
    "        \"berhan\": \"O\",\n",
    "        \"meswkelu\": \"O\",\n",
    "        \"beselam\": \"O\",\n",
    "        \"adersachu\": \"O\",\n",
    "               \n",
    "\n",
    "    }\n",
    " \n",
    "    # Apply labels based on the tokens\n",
    "    for i, token in enumerate(tokens):\n",
    "        # Check if token is in the custom list\n",
    "        if token in custom_tokens:\n",
    "            labels[i] = custom_tokens[token]\n",
    "        # Check if token matches very long numbers (10 digits or more)\n",
    "        elif re.match(r'^\\d{10,}$', token):\n",
    "            labels[i] = 'O'  # Label long numbers as 'O'\n",
    "        # Label prices (e.g., numbers, ETB, Birr, $, etc.)\n",
    "        elif any(pro in token for pro in product_patterns):\n",
    "            labels[i] = 'B-PRODUCT'\n",
    "        elif any(re.match(pattern, token) for pattern in price_patterns):\n",
    "            labels[i] = 'I-PRICE'\n",
    "        # Label locations (predefined locations)\n",
    "        elif any(loc in token for loc in locations):\n",
    "            labels[i] = 'I-LOC'\n",
    "        # Label other tokens as I-PRODUCT\n",
    "        else:\n",
    "            labels[i] = 'I-PRODUCT'\n",
    "    \n",
    "    return labels \n",
    "\n",
    "# Function to combine both NER and custom labels\n",
    "def combine_labels(ner_labels, custom_labels):\n",
    "    final_labels = []\n",
    "    \n",
    "    for ner_label, custom_label in zip(ner_labels, custom_labels):\n",
    "        if ner_label != 'O':  # NER label takes precedence\n",
    "            final_labels.append(ner_label)\n",
    "        else:\n",
    "            final_labels.append(custom_label)  # Otherwise, use custom label\n",
    "    \n",
    "    return final_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    }
   ],
   "source": [
    "# Function to process a message with both NER and custom methods\n",
    "def process_message(message, nlp_pipeline):\n",
    "    tokens = re.findall(r'\\S+', message)  # Tokenize the message\n",
    "    \n",
    "    # Apply NER model\n",
    "    ner_results = nlp_pipeline(message)\n",
    "    ner_labels = map_ner_to_conll(ner_results, tokens)\n",
    "    \n",
    "    # Apply custom labeling\n",
    "    custom_labels = custom_label_prices_locations(tokens)\n",
    "    \n",
    "    # Combine both label sets\n",
    "    final_labels = combine_labels(ner_labels, custom_labels)\n",
    "    \n",
    "    # Return tokens with their combined labels\n",
    "    labeled_tokens = [f\"{token} {label}\" for token, label in zip(tokens, final_labels)]\n",
    "    return \"\\n\".join(labeled_tokens)\n",
    "\n",
    "# Apply the combined processing to each message\n",
    "telegram_data['Labeled_Message'] = telegram_data['Message'].apply(lambda msg: process_message(msg, nlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel Username</th>\n",
       "      <th>ID</th>\n",
       "      <th>Message</th>\n",
       "      <th>Date</th>\n",
       "      <th>Labeled_Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>6211</td>\n",
       "      <td>INIMA JAPAN COFFEE GRINDER\\n\\n·ä®·çç·â∞·äõ ·å•·à´·âµ \\n\\n150...</td>\n",
       "      <td>2025-01-17 06:59:57+00:00</td>\n",
       "      <td>INIMA I-PRODUCT\\nJAPAN I-PRODUCT\\nCOFFEE I-PRO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>6210</td>\n",
       "      <td>INIMA JAPAN COFFEE GRINDER\\n\\n·ä®·çç·â∞·äõ ·å•·à´·âµ \\n\\n150...</td>\n",
       "      <td>2025-01-17 06:59:57+00:00</td>\n",
       "      <td>INIMA I-PRODUCT\\nJAPAN I-PRODUCT\\nCOFFEE I-PRO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>6207</td>\n",
       "      <td>stainless still flower shape cake mold\\n\\nnon ...</td>\n",
       "      <td>2025-01-16 13:41:31+00:00</td>\n",
       "      <td>stainless I-PRODUCT\\nstill I-PRODUCT\\nflower I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>6206</td>\n",
       "      <td>Delux Foldable multifunctional Draying RACK\\n\\...</td>\n",
       "      <td>2025-01-16 10:07:54+00:00</td>\n",
       "      <td>Delux I-PRODUCT\\nFoldable B-PRODUCT\\nmultifunc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@Shageronlinestore</td>\n",
       "      <td>6205</td>\n",
       "      <td>·ä†·àç·âÜ·àç·àà·â∞·â£·àã·âΩ·àÅ·â†·ãµ·åã·àö·ä†·àµ·åà·â•·â∞·äì·àç \\nAutomatic rotating noz...</td>\n",
       "      <td>2025-01-16 09:20:43+00:00</td>\n",
       "      <td>·ä†·àç·âÜ·àç·àà·â∞·â£·àã·âΩ·àÅ·â†·ãµ·åã·àö·ä†·àµ·åà·â•·â∞·äì·àç I-LOC\\nAutomatic I-PRODU...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Channel Username    ID  \\\n",
       "0  @Shageronlinestore  6211   \n",
       "1  @Shageronlinestore  6210   \n",
       "2  @Shageronlinestore  6207   \n",
       "3  @Shageronlinestore  6206   \n",
       "4  @Shageronlinestore  6205   \n",
       "\n",
       "                                             Message  \\\n",
       "0  INIMA JAPAN COFFEE GRINDER\\n\\n·ä®·çç·â∞·äõ ·å•·à´·âµ \\n\\n150...   \n",
       "1  INIMA JAPAN COFFEE GRINDER\\n\\n·ä®·çç·â∞·äõ ·å•·à´·âµ \\n\\n150...   \n",
       "2  stainless still flower shape cake mold\\n\\nnon ...   \n",
       "3  Delux Foldable multifunctional Draying RACK\\n\\...   \n",
       "4  ·ä†·àç·âÜ·àç·àà·â∞·â£·àã·âΩ·àÅ·â†·ãµ·åã·àö·ä†·àµ·åà·â•·â∞·äì·àç \\nAutomatic rotating noz...   \n",
       "\n",
       "                        Date  \\\n",
       "0  2025-01-17 06:59:57+00:00   \n",
       "1  2025-01-17 06:59:57+00:00   \n",
       "2  2025-01-16 13:41:31+00:00   \n",
       "3  2025-01-16 10:07:54+00:00   \n",
       "4  2025-01-16 09:20:43+00:00   \n",
       "\n",
       "                                     Labeled_Message  \n",
       "0  INIMA I-PRODUCT\\nJAPAN I-PRODUCT\\nCOFFEE I-PRO...  \n",
       "1  INIMA I-PRODUCT\\nJAPAN I-PRODUCT\\nCOFFEE I-PRO...  \n",
       "2  stainless I-PRODUCT\\nstill I-PRODUCT\\nflower I...  \n",
       "3  Delux I-PRODUCT\\nFoldable B-PRODUCT\\nmultifunc...  \n",
       "4  ·ä†·àç·âÜ·àç·àà·â∞·â£·àã·âΩ·àÅ·â†·ãµ·åã·àö·ä†·àµ·åà·â•·â∞·äì·àç I-LOC\\nAutomatic I-PRODU...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telegram_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labeled data saved to C:\\Users\\fikad\\Desktop\\10acedamy\\EthioMart-NER-Named-Entity-Recognition-\\Data\\labeled_telegram_data_conll.conll\n"
     ]
    }
   ],
   "source": [
    "# Save the final labeled data to a CoNLL-style file\n",
    "output_file_combined = r'C:\\Users\\fikad\\Desktop\\10acedamy\\EthioMart-NER-Named-Entity-Recognition-\\Data\\labeled_telegram_data_conll.conll'\n",
    "with open(output_file_combined, 'w', encoding='utf-8') as f:\n",
    "    for index, row in telegram_data.iterrows():\n",
    "        f.write(f\"{row['Labeled_Message']}\\n\\n\")\n",
    "\n",
    "\n",
    "print(f\"labeled data saved to {output_file_combined}\")  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Week-5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
